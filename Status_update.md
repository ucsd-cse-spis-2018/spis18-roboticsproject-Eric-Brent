                                                        State of the Project
                                                        
    For our robotics project, we are creating a robot that will sense an object on a custom popsicle-stick hand, and tell the servo to move the hand up and down. Since the beginning of the project, the biggest roadblocks that we have faced are syncing the different equipment we have (including the analog, servo, and infrared sensor), as well as syncing the codes together. We initially focused on having an ultrasound on the palm of our custom-built hand. Therefore, when the ultrasound reaches a value of -1, or there is something blocking the signal, then it would trigger the servo code and thus the handshake. We wrote an elaborate finite state machine code for the servo to complement the ultrasound, and it initially worked; however, we quickly found out that the ultrasound hardware was extremely inconsistent. We got advice from a peer to use an infrared sensor to make much more accurate predictions, and we ended up going with that idea. 

Our next goal was to implement the infrared sensor to take the place of the ultrasound sensor; it would fit on the wrist of the hand, and detect an object touching the hand. We used an LED to make sure that the infrared sensor was indeed detecting a hand, as when an object came closer to the hand and touched the hand, the LED would glow brighter and brighter. We then attempted to implement that code with a finite state machine that we created for our servo. It worked initially, and the infrared sensor and the servo worked in tandem. However, as time went on, our infrared sensor appeared to be faulty, as it would continuously detect an object when none was there. We diagnosed it to be detecting light from outside sources, and our solution was to add an analog to the motherboard (with the guidance of Curt). There, we can set values to the intensity of light observed by the infrared sensor, and set a threshold value for when the infrared code should trigger the servo FSM (finite state machine). During this process, we learned that implementing codes for different sensors and functions into the same file was not a great idea: the GPIO modes were conflicting, it was confusing to the reader and coder when trying to interpret the code, and it just didnâ€™t work. We resolved this issue by placing different functions in different files, and importing them onto a main file to run. Therefore, we can define functions in other files, so we can implement them easily on our main file. 

After writing code for syncing the analog with the infrared sensor and servo, we finally managed to achieve our MVP: create a functional hand that would shake a hand when a hand is placed on the robot palm. Currently, we are attempting to attach the hand onto a cardboard chassis and implement a speaker system onto our raspberry pi. After, we can implement code in the speaker file so it can randomly select audio files to play, and special audio files to play when certain actions are detected. At the moment, we are not in requirement of any assistance; when problems arise in the near future, we will definitely seek out the guidance of mentors and instructors.
